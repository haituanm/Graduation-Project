{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj483pRzT4gE"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "model = models[5]['LSTM'][1]\n",
        "plot_model(model, show_shapes=True, show_layer_names=True)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkOyg2ZtKiYq"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import pandas_ta\n",
        "except ImportError:\n",
        "  !pip install -q gdown pandas_ta streamlit streamlit-pdf-viewer > /dev/null\n",
        "  !gdown 1XoLFPCkuExIehc4yduL2W35VgK3xBZiC\n",
        "  import pandas_ta as ta\n",
        "!curl ipv4.icanhazip.com\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import date, timedelta\n",
        "# from google.colab import drive\n",
        "from plotly import express as px, graph_objects as go, io as pio, subplots\n",
        "# from pypfopt import EfficientFrontier, expected_returns, risk_models --PyPortfolioOpt\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from time import sleep\n",
        "import gdown\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "import psycopg2\n",
        "import requests\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "!unzip -q web_app.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTN3Hwa6ZZoo"
      },
      "outputs": [],
      "source": [
        "!streamlit run About.py &> /dev/null & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K86vv6UjLJq8"
      },
      "outputs": [],
      "source": [
        "conn=psycopg2.connect(\n",
        "    host='btt2qpilkzi0pxzq8vzv-postgresql.services.clever-cloud.com',\n",
        "    port='50013',\n",
        "    database='btt2qpilkzi0pxzq8vzv',\n",
        "    user='ufkrh0a7c7sfgxfain5q',\n",
        "    password='bRhBfciIHwDWwDnPV7vGezZrYDQbsm'\n",
        ")\n",
        "# conn.rollback()\n",
        "\n",
        "cur=conn.cursor()\n",
        "def querier(query):\n",
        "  conn.rollback()\n",
        "  cur.execute(query)\n",
        "  conn.rollback()\n",
        "  return cur.fetchall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6U8Mbh5Kgpr"
      },
      "source": [
        "###2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6xg5Lx_Msx4"
      },
      "outputs": [],
      "source": [
        "def scraper(symbol):\n",
        "  params = {\n",
        "      'Symbol':symbol,\n",
        "      'StartDate':'01/01/2024',\n",
        "      'EndDate':'05/31/2024',\n",
        "      'PageIndex':1,\n",
        "      'PageSize':3000\n",
        "  }\n",
        "  response = requests.get('https://s.cafef.vn/Ajax/PageNew/DataHistory/PriceHistory.ashx', params)\n",
        "  return response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN3MDQ4vCU5f"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "symbols = ['VN30INDEX']#, 'BVH', 'GAS', 'MSN', 'SSI', 'VCB']\n",
        "\n",
        "for symbol in symbols:\n",
        "  output = scraper(symbol)['Data']['Data']\n",
        "  for i in output:\n",
        "    _date = i['Ngay']\n",
        "    symbol = symbol\n",
        "    _open = i['GiaMoCua']\n",
        "    high = i['GiaCaoNhat']\n",
        "    low = i['GiaThapNhat']\n",
        "    volume = i['KhoiLuongKhopLenh']\n",
        "    close = i['GiaDongCua']\n",
        "    data.append((_date, symbol, _open, high, low, volume, close))\n",
        "  sleep(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE3tkpYxGOR_"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data, columns = ['date', 'symbol', 'open', 'high', 'low', 'volume', 'close'])\n",
        "print(df.shape, '\\n')\n",
        "print(df.isna().sum(), '\\n')\n",
        "df.info()\n",
        "df.to_csv('VN30.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oC1J74OO366"
      },
      "outputs": [],
      "source": [
        "df['date'] = pd.to_datetime(df['date'], format = '%d/%m/%Y')\n",
        "\n",
        "close = df.pivot_table(index = 'date', columns = 'symbol', values = 'close')\n",
        "close = close[close.index < '2024-06-01']\n",
        "close.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lPEIq6aDXx-"
      },
      "outputs": [],
      "source": [
        "stock = pd.read_csv('VN30.csv')\n",
        "stock['date'] = pd.to_datetime(stock['date'], format='%d/%m/%Y')\n",
        "stock['symbol'].replace('VN30INDEX', 'VN30', inplace=True)\n",
        "stock = stock[stock.date > '2014-12-31']\n",
        "\n",
        "holiday = pd.read_csv('Holiday.csv')\n",
        "holiday['date'] = holiday.month + '-' + holiday.year.astype(str)\n",
        "holiday['date'] = holiday.date.str.replace(' ', '-')\n",
        "holiday['date'] = pd.to_datetime(holiday['date'])\n",
        "holiday = holiday[holiday.date.between('2015-01-05', '2024-01-31')]\n",
        "holiday.set_index('date', inplace=True)\n",
        "holiday.holiday.replace({\n",
        "    'Day off for Hung Kings Festival': 'Hung Kings Commemoration Day',\n",
        "    'Day off for International Labor Day': 'International Labor Day',\n",
        "    'Day off for International New Year\\'s Day': 'International New Year Day',\n",
        "    'Day off for Liberation Day/Reunification Day': 'Reunification Day',\n",
        "    'Hung Kings Festival': 'Hung Kings Commemoration Day',\n",
        "    'Hung Kings Festival holiday': 'Hung Kings Commemoration Day',\n",
        "    'Independence Day Holiday': 'Independence Day',\n",
        "    'Independence Day observed': 'Independence Day',\n",
        "    'International New Year\\'s Day': 'International New Year Day',\n",
        "    'International New Year\\'s Eve': 'International New Year Day',\n",
        "    'Liberation Day/Reunification Day': 'Reunification Day',\n",
        "    'Liberation Day/Reunification Day Holiday': 'Reunification Day',\n",
        "    'New Year\\'s Day Holiday': 'International New Year Day',\n",
        "    'Tet holiday': 'Tet Holiday',\n",
        "    'Vietnamese New Year': 'Tet Holiday',\n",
        "    'Vietnamese New Year\\'s Eve': 'Tet Holiday'\n",
        "}, inplace=True)\n",
        "holiday.drop(['month', 'year'], axis=1, inplace=True)\n",
        "\n",
        "pivot = stock.pivot_table(index='date', columns='symbol', values=['open', 'high', 'low', 'volume', 'close'])\n",
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XgMJS4JLxwV"
      },
      "source": [
        "###3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6d_e1XMRhLl"
      },
      "outputs": [],
      "source": [
        "def skew_kurtosis(start_date, end_date):\n",
        "  data = pivot.close.drop('VN30', axis=1)\n",
        "  data = 100*data[(data.index >= start_date) & (data.index <= end_date)].pct_change()[1:]\n",
        "  return pd.DataFrame({'mean':data.mean(), 'skewness':data.skew(), 'kurtosis':data.kurtosis()}, index=['BVH', 'GAS', 'MSN', 'SSI', 'VCB']).round(2)\n",
        "\n",
        "skew_kurtosis('2023-01-01', '2023-12-31')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq9O84q1NnSS"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(pivot.close.to_records()).drop(['date', 'VN30'], axis=1).pct_change().cov().round(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9Fbm2VEpjeu"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(pivot.close.to_records()).drop('date', axis=1).corr().round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5BO0rZzQA7p"
      },
      "outputs": [],
      "source": [
        "drop_indices = []\n",
        "previous_day = holiday.index[0]\n",
        "for d in holiday.index[1:]:\n",
        "  if d == previous_day+timedelta(days=1):\n",
        "    drop_indices.append(d)\n",
        "  else:\n",
        "    drop_indices.append(previous_day)\n",
        "  previous_day = d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_66LUtDP-zyT"
      },
      "outputs": [],
      "source": [
        "def line_chart(data, start_date, end_date, symbol):\n",
        "  data = data[(data.index >= start_date) & (data.index <= end_date)]\n",
        "  fig = px.scatter(data, x=data.index, y=symbol, trendline='ols', trendline_color_override=False if type(symbol) == list else 'yellow', template='plotly_dark')\n",
        "  if type(symbol) == str:\n",
        "    for d in holiday[(~holiday.index.isin(drop_indices)) & (holiday.index.year==data.index.year[0])].index:\n",
        "      fig.add_vline(x=d, label=dict(text=holiday.loc[d,'holiday']))\n",
        "      # fig.add_vline(x=d, line=dict(width=250), opacity=0.1)\n",
        "      fig.add_vrect(x0=d-timedelta(days=20), x1=d+timedelta(days=20), fillcolor='white', opacity=0.1)\n",
        "  fig.update_traces(mode='lines', connectgaps=True)\n",
        "  fig.update_layout(title=f'{symbol} Close From {start_date} To {end_date}', margin=dict(l=5, r=5, t=50, b=5), height=360, xaxis_title=None, yaxis_title=None, legend_title='Symbols')\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7OTyDDD1T4k"
      },
      "outputs": [],
      "source": [
        "line_chart(pivot.close, '2023-12-01', '2024-04-30', 'VN30').show()\n",
        "\n",
        "#Đại dịch Covid-19 bắt đầu ảnh hưởng tới TTCK Việt Nam từ cuối tháng 1-2020, sớm hơn thế giới tới gần một tháng.\n",
        "#Phản ứng lo sợ của nhà đầu tư trước các bất định do dịch bệnh gây ra đã dẫn đến một đợt sụt giảm nhanh và mạnh chưa từng thấy.\n",
        "#Chỉ số VN30 chỉ trong hai tháng đã giảm gần 30% và xuống mức thấp nhất trong vòng bốn năm.\n",
        "#Tuy nhiên, thị trường đã phục hồi nhanh chóng trong chín tháng còn lại với mức tăng trưởng hơn 75% kể từ đáy.\n",
        "#Sự phục hồi của VN30 đến từ việc kiểm soát dịch bệnh tốt trong nước của Chính phủ, các biện pháp kích thích tiền tệ và tài khóa kịp thời, đặc biệt là dòng tiền “rẻ” nhờ môi trường lãi suất thấp đã kích thích một lượng vốn lớn đổ vào TTCK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw072jrSo8gv"
      },
      "outputs": [],
      "source": [
        "line_chart(pivot.close, '2021-01-01', '2021-12-31', 'VN30').show()\n",
        "\n",
        "#Năm 2021, chỉ số VN30 nhiều lần thiết lập đỉnh lịch sử mới, cao nhất là vào ngày 25/11 khi chạm mốc 1.572,46 điểm. Đây cũng là mức cao nhất trong lịch sử TTCK tính đến thời điểm này.\n",
        "#Trước đó, ngay trong ngày đầu tiên của quý 2/2021, VN30 đã chính thức vượt mốc 1.200 điểm - mốc kỷ lục được thiết lập từ 2018.\n",
        "#Tính đến ngày 31/12/2021, VN30 đạt 1.535,71 điểm, tăng hơn 43% so với cuối năm 2020.\n",
        "#Làn sóng nhà đầu tư cá nhân mới tham gia thị trường là một trong những nhân tố quan trọng thúc đẩy tăng trưởng mạnh mẽ của thanh khoản trong giai đoạn này.\n",
        "#Theo thống kê từ các công ty chứng khoán, năm 2021, người dân đã chuyển thêm khoảng 3 tỷ USD vào đầu tư chứng khoán."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFw773LI2jU_"
      },
      "outputs": [],
      "source": [
        "line_chart(pivot.close, '2022-01-01', '2022-12-31', 'VN30').show()\n",
        "\n",
        "#Sau một năm 2021 thăng hoa, chỉ số VN30 tiếp tục duy trì ở mức cao trong 3 tháng đầu năm 2022 trước khi bắt đầu tụt dốc từ đầu tháng 4.\n",
        "#Đến 30/12, VN30 xuống còn 1.005,19 điểm, thấp hơn 35% so với mức đỉnh hồi đầu tháng 4.\n",
        "\n",
        "#Đà giảm của VN30 được lý giải bởi nhiều nguyên nhân như thị trường liên tục gặp những cú sốc như các vụ khởi tố lãnh đạo cấp cao tại Tập đoàn FLC, Tân Hoàng Minh, Vạn Thịnh Phát,...\n",
        "#Đồng thời, một số yếu tố khác cũng ảnh hưởng đến thị trường như lãi suất tăng; thắt chặt tín dụng đối với các phân khúc cho vay rủi ro cao, bao gồm đầu tư bất động sản, chứng khoán,...\n",
        "#Ngoài ra, tình hình quốc tế như cuộc chiến Nga - Ukraine khiến giá dầu thô tăng vọt, TQ áp dụng chính sách \"Zero-COVID\" dẫn đến chuỗi cung ứng bị đứt gãy, FED liên tục tăng lãi suất nhằm kiềm chế lạm phát,...\n",
        "#Qua đó ảnh hưởng tâm lý các nhà đầu tư cá nhân - bộ phận chiếm đến 90% cơ cấu nhà đầu tư trên thị trường chứng khoán."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nv5Ra_AhTp3k"
      },
      "outputs": [],
      "source": [
        "line_chart(pivot.close, '2023-01-01', '2023-12-31', 'VN30').show()\n",
        "\n",
        "#Thị trường nhìn chung diễn biến tích cực cho đến đầu tháng 9, có thời điểm VN30 đạt hơn 1.255 điểm.\n",
        "#Lý do đến từ việc nới lỏng chính sách tiền tệ của Ngân hàng Nhà nước, với 4 lần cắt giảm lãi suất điều hành nhằm hỗ trợ tăng trưởng kinh tế.\n",
        "#Nhà đầu tư cá nhân là động lực chính cho giai đoạn tăng điểm kéo dài trong 4 tháng, từ cuối tháng 4 đến hết tháng 8/2023, dù khối ngoại có động thái bán ròng.\n",
        "#Dòng tiền cá nhân nhập cuộc thận trọng giai đoạn đầu, nhưng mạnh mẽ hơn từ cuối tháng 4 đã giúp VN30 dần đi lên, khiến VN trở thành một trong những chỉ số chứng khoán tăng điểm ấn tượng trên thế giới.\n",
        "\n",
        "#Tuy nhiên, trong vòng 2 tháng, thành quả của giai đoạn trước gần như tiêu tan sau nhịp điều chỉnh chủ yếu do yếu tố ngoại biên.\n",
        "#Áp lực tỷ giá, dẫn đến Ngân hàng Nhà nước thực hiện biện pháp can thiệp là rút một lượng lớn tiền về hệ thống thông qua kênh tín phiếu.\n",
        "#Trong khi đó, khối ngoại duy trì động thái bán ròng. Tâm lý nhà đầu tư nội bị ảnh hưởng khiến chỉ số giảm điểm, dù yếu tố vĩ mô trong nước vẫn tích cực.\n",
        "#(GDP quý III tăng 5,3%, quý IV tăng 6,72%, lạm phát được kiểm soát, lãi suất tiếp tục giảm,...)\n",
        "#Giai đoạn cuối năm, VN30 dao động quanh ngưỡng 1.100 điểm, đóng cửa phiên 29/12 tại 1.131,46 điểm.\n",
        "#Thị trường chứng khoán năm 2023 có độ nhạy cao với chính sách tiền tệ.\n",
        "#Thị trường hưng phấn, tăng mạnh sau động thái cắt giảm lãi suất liên tiếp của Ngân hàng Nhà nước và phản ứng tiêu cực khi có động thái hút tiền từ cơ quan này để ổn định tỷ giá.\n",
        "#Hai tháng cuối năm, sau khi Ngân hàng Nhà nước ngừng hút tiền, thanh khoản hệ thống ngân hàng ổn định trở lại, diễn biến thị trường chứng khoán hồi phục nhẹ rồi đi ngang."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPIGbTXDgH4E"
      },
      "outputs": [],
      "source": [
        "def candlestick_chart(data, start_date, end_date, symbol):\n",
        "  data = data[(data.index >= start_date) & (data.index <= end_date)]\n",
        "  fig = go.Figure([go.Candlestick(x=data.index, open=data.open[symbol], high=data.high[symbol], low=data.low[symbol], close=data.close[symbol], showlegend=False)])\n",
        "  # fig.add_trace(go.Scatter(x=data.index, y=ta.sma(data.close[symbol], length), line_color='blue', name='SMA%s' %length))\n",
        "  fig.add_trace(go.Scatter(x=data.index, y=ta.ema(data.close[symbol], 10), line_color='red', name='EMA10'))\n",
        "  fig.add_trace(go.Scatter(x=data.index, y=ta.ema(data.close[symbol], 20), line_color='green', name='EMA20'))\n",
        "  fig.add_trace(go.Scatter(x=data.index, y=ta.ema(data.close[symbol], 50), line_color='blue', name='EMA50'))\n",
        "  fig.add_trace(go.Scatter(x=data.index, y=ta.bbands(data.close[symbol], 20).iloc[:,0], line_color='white', line={'dash':'dash'}, showlegend=False))\n",
        "  fig.add_trace(go.Scatter(x=data.index, y=ta.bbands(data.close[symbol], 20).iloc[:,2], line_color='white', line={'dash':'dash'}, showlegend=False))\n",
        "  fig.update_layout(title=f'{symbol} Volatility From {start_date} To {end_date}', margin=dict(l=5, r=5, t=50, b=5), height=360, template='plotly_dark', xaxis_rangeslider_visible=False)\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxOHgbibUlwx"
      },
      "outputs": [],
      "source": [
        "candlestick_chart(pivot, '2023-07-01', '2023-12-31', 'VCB').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvT719lN40mk"
      },
      "outputs": [],
      "source": [
        "def bar_chart(symbol):\n",
        "  data = {'year':[], 'change':[]}\n",
        "  for year in range(2015, 2024):\n",
        "    data['year'].append(year)\n",
        "    year_open = float(pivot[pivot.index == pivot[pivot.index.year == year].index.min()].open[symbol])\n",
        "    year_close = float(pivot[pivot.index == pivot[pivot.index.year == year].index.max()].close[symbol])\n",
        "    data['change'].append(100*(year_close/year_open - 1))\n",
        "  data = pd.DataFrame(data)\n",
        "  fig = px.line(data, x='year', y='change')\n",
        "  fig['data'][0]['line']['color'] = 'white'\n",
        "  fig.add_bar(x=data.year, y=data.change, text=data.change.round(2), textposition='outside')\n",
        "  fig.update_traces(marker_color=np.where(np.array(data['change']) > 0, 'green', 'red'), showlegend=False, textfont_size=8)\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-Fh2XPePmOq"
      },
      "outputs": [],
      "source": [
        "fig = subplots.make_subplots(rows=2, cols=5, vertical_spacing=0.1, specs=[[{}, {}, {}, {}, {}], [None, {'colspan':3}, None, None, None]], subplot_titles=pivot.close.columns)\n",
        "for s, i in zip(['BVH', 'GAS', 'MSN', 'SSI', 'VCB'], [1, 2, 3, 4, 5]):\n",
        "  fig.add_trace(bar_chart(s).data[0], row=1, col=i)\n",
        "  fig.add_trace(bar_chart(s).data[1], row=1, col=i)\n",
        "fig.add_trace(bar_chart('VN30').data[0], row=2, col=2)\n",
        "fig.add_trace(bar_chart('VN30').data[1], row=2, col=2)\n",
        "fig.update_layout(title='Stock Price Change Each Year', margin=dict(l=5, r=5, t=75, b=5), template='plotly_dark')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u97uEfJZtnhY"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame(scaler.fit_transform(pivot.close), columns=['BVH', 'GAS', 'MSN', 'SSI', 'VCB', 'VN30'], index=pivot.index)\n",
        "line_chart(data, '2015-01-01', '2023-12-31', ['BVH', 'GAS', 'MSN', 'SSI', 'VCB']).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC8ItuAOfRCk"
      },
      "outputs": [],
      "source": [
        "drop_indexes0 = []\n",
        "previous_day = holiday.index[-1]\n",
        "for d in holiday.index[-2::-1]:\n",
        "  if d == previous_day-timedelta(days=1):\n",
        "    drop_indexes0.append(d)\n",
        "  previous_day = d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgvBygqzJbke"
      },
      "outputs": [],
      "source": [
        "line_chart(pivot.close-pivot.open, '2020-01-01', '2020-12-31', 'BVH').show()\n",
        "line_chart(pivot.volume, '2020-01-01', '2020-12-31', 'BVH').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdxATRwqcWFl"
      },
      "source": [
        "###4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KV77dj2UduEG"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import AveragePooling1D, Conv1D, Dense, Dropout, Flatten, GlobalAveragePooling1D, Input, LayerNormalization, LSTM, MaxPooling1D, MultiHeadAttention, SimpleRNN\n",
        "from keras.models import load_model, Model, Sequential\n",
        "from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, r2_score\n",
        "import keras\n",
        "import keras.backend as K\n",
        "models = {5:{}, 10:{}, 20:{}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYQj7vMjcg5M"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "model_list = ['CNN', 'RNN', 'LSTM']\n",
        "timestep = 5\n",
        "epochs = 8\n",
        "batch_size = 8\n",
        "scaler = MinMaxScaler()\n",
        "def input_transform(input, timestep, transform_only=2):\n",
        "  X = []\n",
        "  y = []\n",
        "  if transform_only == 1: data = scaler.transform(input).squeeze()\n",
        "  else: data = scaler.fit_transform(input).squeeze()\n",
        "  for start_index in range(len(data)):\n",
        "    end_index = start_index + timestep\n",
        "    if end_index > len(data) - 1:\n",
        "      break\n",
        "    X.append(data[start_index:end_index])\n",
        "    y.append(data[end_index])\n",
        "  X, y = np.array(X), np.array(y)\n",
        "  return X.reshape(X.shape[0], X.shape[1], 1), y.reshape(-1,1)\n",
        "\n",
        "input = pd.concat([pivot.close[['VN30']][:-22], close[:]])[['VN30']].dropna()\n",
        "X, y = input_transform(input, 5)\n",
        "X_train, y_train = X[:1724], y[:1724] #input_transform(input[:-59], timestep)\n",
        "X_test, y_test = X[1724:], y[1724:] #input_transform(input[-59:], timestep, 1)\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "  return K.sqrt(K.mean(K.square(y_true-y_pred)))\n",
        "\n",
        "joblib.dump(scaler, 'MinMaxScaler.sav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61KpS6MQeNrH"
      },
      "outputs": [],
      "source": [
        "input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idaBZwVb8KNF"
      },
      "outputs": [],
      "source": [
        "# !mv *.py ./pages\n",
        "# conn.rollback()\n",
        "cur.execute(open('PostgreSQL_query.txt', 'r').read())\n",
        "conn.rollback()\n",
        "result = pd.DataFrame(cur.fetchall(), columns=['date', 'trader_id', 'symbol', 'price', 'buy_quantity', 'sell_quantity'])\n",
        "result = result.astype({'trader_id':str, 'price':int})\n",
        "result['date'] = pd.to_datetime(result.date, format='%Y-%m-%d').dt.date\n",
        "result\n",
        "\n",
        "# fig = px.line(result, x='date', y=['buy_quantity', 'sell_quantity'])\n",
        "# fig.update_layout(legend_title=None, legend=dict(x=0, y=1, bordercolor='White', borderwidth=2), margin=dict(l=5, r=5, t=5, b=5), xaxis=dict(showgrid=False), xaxis_title=None, yaxis_title=None, template='plotly_dark', height=360)\n",
        "# fig.show()\n",
        "\n",
        "# blackbox.ai/chat/YIxl8Z3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HkCu2tXHMDKW"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "prompt = f'''From now on, you will play a role as a senior analyst in stock trading with Python and its module pandas_ta are your main analysis tools. You are capable of decoding complicated technical indicators and unpredictable market movements. Your jobs now are to provide detailed explanations and clear insights from given figures; make possible predictions and offer valuable observations.\n",
        "What the price trend of this stock will be in the next few days?\n",
        "Data today of BVH:\n",
        "- Close: {figures.iloc[-3,0]}\n",
        "- EMA_10: {figures.iloc[-3,1]}\n",
        "- EMA_20: {figures.iloc[-3,2]}\n",
        "- BBL_20: {figures.iloc[-3,3]}\n",
        "- BBM_20: {figures.iloc[-3,4]}\n",
        "- BBU_20: {figures.iloc[-3,5]}\n",
        "- RSI_20: {figures.iloc[-3,8]}\n",
        "- CCI_20: {figures.iloc[-3,9]}\n",
        "Data yesterday of BVH:\n",
        "- Close: {figures.iloc[-4,0]}\n",
        "- EMA_10: {figures.iloc[-4,1]}\n",
        "- EMA_20: {figures.iloc[-4,2]}\n",
        "- BBL_20: {figures.iloc[-4,3]}\n",
        "- BBM_20: {figures.iloc[-4,4]}\n",
        "- BBU_20: {figures.iloc[-4,5]}\n",
        "- RSI_20: {figures.iloc[-4,8]}\n",
        "- CCI_20: {figures.iloc[-4,9]}'''\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU33NAhIj0UZ"
      },
      "outputs": [],
      "source": [
        "x = np.arange(len(input))\n",
        "fig = go.Figure(go.Scatter(x=x[:len(y_train)], y=y_train.squeeze(), name='Train data'))\n",
        "fig.add_trace(go.Scatter(x=x[len(y_train):], y=y_test.squeeze(), name='Test data'))\n",
        "fig.update_layout(\n",
        "    legend_title=None,\n",
        "    margin=dict(l=5, r=5, t=5, b=5),\n",
        "    xaxis=dict(showgrid=False),\n",
        "    xaxis_title=None,\n",
        "    yaxis_title=None,\n",
        "    template='plotly_dark',\n",
        "    height=360, width=720\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo7HfTHSSsaa"
      },
      "outputs": [],
      "source": [
        "def model_selection(model_name, timestep):\n",
        "#model1 = Sequential()\n",
        "#model1.add(Conv1D(filters=50, kernel_size=2, activation='relu', input_shape=(timestep,1)))\n",
        "#model1.add(MaxPooling1D(pool_size=2))\n",
        "#model1.add(Flatten())\n",
        "#model1.add(Dense(100, activation='relu'))\n",
        "#model1.add(Dense(1))\n",
        "\n",
        "#model2 = Sequential()\n",
        "#model2.add(SimpleRNN(50, activation='tanh', return_sequences=True, input_shape=(timestep,1)))\n",
        "#model2.add(Dropout(0.2))\n",
        "#model2.add(SimpleRNN(50, activation='tanh', return_sequences=True))\n",
        "#model2.add(SimpleRNN(50, activation='tanh', return_sequences=True))\n",
        "#model2.add(SimpleRNN(50))\n",
        "#model2.add(Dense(1))\n",
        "\n",
        "#model3 = Sequential()\n",
        "#model3.add(LSTM(128, return_sequences=True, input_shape=(timestep,1)))\n",
        "  # model3.add(Dropout(0.2))\n",
        "#model3.add(LSTM(64, return_sequences=False))\n",
        "  # model3.add(Dropout(0.2))\n",
        "#model3.add(LSTM(25))\n",
        "  # model3.add(Dropout(0.2))\n",
        "#model3.add(Dense(1))\n",
        "\n",
        "#model4 = Sequential()\n",
        "\n",
        "  if model_name == 'CNN': return model1, model_name\n",
        "  elif model_name == 'RNN': return model2, model_name\n",
        "  elif model_name == 'LSTM': return model3, model_name\n",
        "  elif model_name == 'Transformer': return model4, model_name\n",
        "\n",
        "def model_running(model_selection, model_name):\n",
        "  model_selection.compile(loss='mse', optimizer='adam')\n",
        "  es = EarlyStopping(patience=5, verbose=1)\n",
        "  mc = ModelCheckpoint(f'{timestep}_{model_name}_model_{epochs}-{batch_size}.keras', save_best_only=True, verbose=0)\n",
        "  history = model_selection.fit(X_train, y_train, callbacks=[mc], epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
        "\n",
        "  return history\n",
        "\n",
        "for timestep in [5, 10, 20]:\n",
        "  X, y = input_transform(input, timestep)\n",
        "  X_train, y_train = X[:1724], y[:1724]\n",
        "  for m in model_list:\n",
        "    print(m)\n",
        "    model, model_name = model_selection(m, timestep)\n",
        "    history = model_running(model, model_name)\n",
        "    models[timestep].update({m:[history, model]})\n",
        "\n",
        "joblib.dump(models, f'Models_using_MinMaxScaler_{epochs}-{batch_size}.sav')\n",
        "!rm *.keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6poGjBNLY5Cd"
      },
      "outputs": [],
      "source": [
        "buy_quantity = []\n",
        "sell_quantity = []\n",
        "while 1:\n",
        "  b_q_v = np.random.choice(range(0,700,100), 77)\n",
        "  s_q_v = np.random.choice(range(0,1000,100), 77)\n",
        "  if (-1 < b_q_v.sum() - s_q_v.sum() < 501) and (s_q_v[0] <= b_q_v[0]):\n",
        "    buy_quantity.append(b_q_v)\n",
        "    sell_quantity.append(s_q_v)\n",
        "    print(len(buy_quantity), end=' ')\n",
        "  if len(sell_quantity) == 5: break\n",
        "# np.concatenate(buy_quantity).sum() - np.concatenate(sell_quantity).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHDKZcmF58so"
      },
      "outputs": [],
      "source": [
        "cur.execute('SELECT symbol, SUM(buy_quantity-sell_quantity), SUM(price*(sell_quantity-buy_quantity)) FROM \"log\" GROUP BY ROLLUP(symbol);')\n",
        "conn.rollback()\n",
        "pd.DataFrame(cur.fetchall(), columns=['symbol', 'number of shares left', 'earn/lose'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DDbcRhbW-G8"
      },
      "outputs": [],
      "source": [
        "for t in [('BVH',0), ('GAS',1), ('MSN',2), ('SSI',3), ('VCB',4)]:\n",
        "  for (d, b_q, s_q) in zip(result[result.symbol==t[0]].date.sort_values(), buy_quantity[t[1]], sell_quantity[t[1]]):\n",
        "    cur.execute(f'UPDATE \"log\" SET buy_quantity={b_q}, sell_quantity={s_q} WHERE symbol=\\'{t[0]}\\' AND trading_date=\\'{d}\\'')\n",
        "    conn.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ5Gtm82wpqe"
      },
      "outputs": [],
      "source": [
        "custom_objects={'rmse':rmse}\n",
        "with keras.utils.custom_object_scope(custom_objects):\n",
        "  models = joblib.load('Models_using_MinMaxScaler_8-8.sav')\n",
        "fig = subplots.make_subplots(rows=3, cols=3, vertical_spacing=0.05, horizontal_spacing=0.03, subplot_titles=model_list, shared_xaxes=True)\n",
        "for model_sel, col in zip(model_list, [1,2,3]):\n",
        "  history = models[5][model_sel][0]\n",
        "  fig.add_trace(px.line(y=[history.history['loss'], history.history['val_loss']]).data[0], row=1, col=col)\n",
        "  fig.add_trace(px.line(y=[history.history['loss'], history.history['val_loss']]).data[1], row=1, col=col)\n",
        "\n",
        "  history = models[10][model_sel][0]\n",
        "  fig.add_trace(px.line(y=[history.history['loss'], history.history['val_loss']]).data[0], row=2, col=col)\n",
        "  fig.add_trace(px.line(y=[history.history['loss'], history.history['val_loss']]).data[1], row=2, col=col)\n",
        "\n",
        "  history = models[20][model_sel][0]\n",
        "  fig.add_trace(px.line(y=[history.history['loss'], history.history['val_loss']]).data[0], row=3, col=col)\n",
        "  fig.add_trace(px.line(y=[history.history['loss'], history.history['val_loss']]).data[1], row=3, col=col)\n",
        "fig.update_layout(showlegend=False, margin=dict(l=5, r=5, t=30, b=5), template='plotly_dark', height=480)\n",
        "fig.for_each_yaxis(lambda y: y.update(showgrid=False))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA0xPHpSXlFY"
      },
      "outputs": [],
      "source": [
        "def model_evaluation(y_test_true, y_test_pred, model_name):\n",
        "  print(model_name)\n",
        "  print('MAE: %.2f' %mae(y_test_true, y_test_pred))\n",
        "  print('RMSE: %.2f' %np.sqrt(mse(y_test_true, y_test_pred)))\n",
        "  print('R^2: %.2f' %r2_score(y_test_true, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C57fsx15mVp"
      },
      "outputs": [],
      "source": [
        "timestep = 5\n",
        "X, y = input_transform(input, timestep, 1)\n",
        "X_test, y_test = X[1724:], y[1724:]\n",
        "fig = subplots.make_subplots(rows=1, cols=3, horizontal_spacing=0.03, subplot_titles=model_list, shared_yaxes=True)\n",
        "for model_sel, col in zip(model_list, [1,2,3]):\n",
        "  model = models[timestep][model_sel][1]\n",
        "  # y_train_pred = model.predict(X_train)\n",
        "  # y_train_pred = scaler.inverse_transform(y_train_pred)\n",
        "  # y_train_true = scaler.inverse_transform(y_train)\n",
        "\n",
        "  y_test_pred = model.predict(X_test)\n",
        "  # y_test_pred += np.std(X_test, axis=1)/5\n",
        "  y_test_pred = scaler.inverse_transform(y_test_pred)\n",
        "  y_test_true = scaler.inverse_transform(y_test)\n",
        "\n",
        "  fig.add_trace(px.line(y=[y_test_pred.squeeze(), y_test_true.squeeze()]).data[0], row=1, col=col)\n",
        "  fig.add_trace(px.line(y=[y_test_pred.squeeze(), y_test_true.squeeze()]).data[1], row=1, col=col)\n",
        "  model_evaluation(y_test_true, y_test_pred, model_sel)\n",
        "fig.update_layout(title=timestep, showlegend=False, margin=dict(l=5, r=5, t=50, b=5), template='plotly_dark', height=240)\n",
        "for figure in fig.data:\n",
        "  figure['x'] = input.index[-len(X_test):]\n",
        "# fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdIGDaqVKyNs"
      },
      "outputs": [],
      "source": [
        "def ai_ta(prompt):\n",
        "  payload = {\n",
        "      'agentMode': {},\n",
        "      'codeModelMode': True,\n",
        "      'githubToken': None,\n",
        "      'id': 'Jslb1W7',\n",
        "      'isChromeExt': False,\n",
        "      'isMicMode': False,\n",
        "      'messages': [{'id': 'Jslb1W7', 'content': prompt, 'role': 'user'}],\n",
        "      'previewToken': None,\n",
        "      'trendingAgentMode': {},\n",
        "      'userId': '87d93ba7-d13d-4caa-a348-bf0f0200301b'\n",
        "  }\n",
        "  response = requests.post('https://www.blackbox.ai/api/chat', json=payload)\n",
        "  return response.text\n",
        "response = ai_ta(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0ol-F7NWAni"
      },
      "source": [
        "###5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ij_2D3DOnGgO"
      },
      "outputs": [],
      "source": [
        "with pd.ExcelWriter('Stock_price.xlsx') as writer:\n",
        "  for col in ['open', 'high', 'low', 'close', 'volume']:\n",
        "    pd.DataFrame(pivot[col].to_records()).to_excel(writer, sheet_name=col, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IodbMWqZS804"
      },
      "outputs": [],
      "source": [
        "def model_selection(model_name, timestep):\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(timestep,1)))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(AveragePooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(timestep,1)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(AveragePooling1D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(32, activation='relu', return_sequences=True, input_shape=(timestep,1)))\n",
        "model.add(SimpleRNN(32, activation='relu', return_sequences=True))\n",
        "model.add(SimpleRNN(64, activation='relu', return_sequences=True))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, activation='relu', return_sequences=True, input_shape=(timestep,1)))\n",
        "model.add(LSTM(32, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2XgMJS4JLxwV"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}